{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using a JSON file, you can point to it in the code block below. Otherwise, use the second code block to fill out a dict that describes the dataset you're generating. Your data should look something like this:\n",
    "``` \n",
    "data_descriptor_json = {\n",
    "  \"defaultLabelColumn\": \"recommendation\", #the default label to be predicted\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"id\": \"age\", #whatever the field contains\n",
    "      \"type\": \"continuous\", #or continuous, or binary\n",
    "      \"values\": {\n",
    "        #if categorical or binary\n",
    "        \"categories\": [],\n",
    "        #if continuous:\n",
    "        \"min\": 0,\n",
    "        \"max\": 100\n",
    "      }\n",
    "    }\n",
    "   ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_file.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-79f9f084a038>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_json_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'your_file.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_descriptor_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_json_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_file.json'"
     ]
    }
   ],
   "source": [
    "data_json_file = open('your_file.json')\n",
    "data_descriptor_json = json.read(data_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'defaultLabelColumn': 'Alert', 'fields': [{'id': 'Alert', 'type': 'continuous', 'values': {'min': 0, 'max': 100}}, {'id': 'Cars', 'type': 'continuous', 'values': {'min': 0, 'max': 50}}]}\n",
      "\n",
      "Alert\n",
      "Cars\n"
     ]
    }
   ],
   "source": [
    "data_descriptor_json = {\n",
    "  \"defaultLabelColumn\": \"Alert\", \n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"id\": \"Alert\", \n",
    "      \"type\": \"continuous\", \n",
    "      \"values\": {\n",
    "        \"min\": 0,\n",
    "        \"max\": 100\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "       \"id\": \"Cars\",\n",
    "      \"type\": \"continuous\",\n",
    "      \"values\": {\n",
    "        \"min\": 0,\n",
    "        \"max\": 50\n",
    "      }\n",
    "    }\n",
    "   ]\n",
    "}\n",
    "\n",
    "print(data_descriptor_json)\n",
    "fields = data_descriptor_json['fields']\n",
    "label = data_descriptor_json['defaultLabelColumn']\n",
    "print()\n",
    "for x in fields:\n",
    "    print(x[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_values = {\n",
    "    \"Cars\": \"linearPositive\",\n",
    "}\n",
    "\n",
    "correlation_valuesNone = {\n",
    "    \"temperature\": \"noCorrelation\",\n",
    "    \"people\": \"noCorrelation\",\n",
    "    \"dayOfMonth\": \"noCorrelation\",\n",
    "    \"antellope\": \"noCorrelation\",\n",
    "    \"rhino\": \"noCorrelation\",\n",
    "    \"elephant\": \"noCorrelation\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we simply define the relationship our variables should have and the percentage of predictions that should *not* meet that relationship - (randomly generated) predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "##In all of these: x is the randomly generated numerical label we're trying to predict\n",
    "##Then we're reverse-engineering a possible feature input that would correlate to that numerical value\n",
    "def gauss(lmin, lmax, fmin, fmax, x):\n",
    "    lmin = float(lmin-1)\n",
    "    lmax = float(lmax)\n",
    "    fmin = float(fmin)\n",
    "    fmax = float(fmax)\n",
    "    x = float(x)\n",
    "    \n",
    "    #Figure out center of bell curve based on feature mins and max\n",
    "    center = (fmin + fmax) / 2\n",
    "    #Figure out distance from center to ends, which is then broken into 4 quadrants for standard dev in next step\n",
    "    dist = fmax - center\n",
    "    #determine width of a single standard deviation, then add a little extra to make it not completely approach 0 at endpoints\n",
    "    width = dist/4 + math.sqrt(dist / 4)\n",
    "    \n",
    "    temp = x - lmin\n",
    "    temp = temp / (lmax - lmin)\n",
    "    #print(\"x: \" + str(x) + \"\\t temp: \" + str(temp))\n",
    "    temp = math.log(temp)\n",
    "    temp = temp * -2 * width * width\n",
    "    \n",
    "    #need this because inverse gaussian curve isn't a function\n",
    "    if(random.randint(1, 2) == 1):\n",
    "        #positive square root\n",
    "        temp = math.sqrt(temp)\n",
    "    else:\n",
    "        #negative square root\n",
    "        temp = -1 * math.sqrt(temp)\n",
    "    \n",
    "    temp = temp + center\n",
    "    return temp\n",
    "\n",
    "def linearPositive(lmin, lmax, fmin, fmax, x):\n",
    "    lmin = float(lmin)\n",
    "    lmax = float(lmax)\n",
    "    fmin = float(fmin)\n",
    "    fmax = float(fmax)\n",
    "    x = float(x)\n",
    "    slope = (lmax - lmin)/(fmax - fmin)\n",
    "    \n",
    "    return ((x-lmin)/slope) + fmin\n",
    "\n",
    "def linearNegative(lmin, lmax, fmin, fmax, x):\n",
    "    lmin = float(lmin)\n",
    "    lmax = float(lmax)\n",
    "    fmin = float(fmin)\n",
    "    fmax = float(fmax)\n",
    "    x = float(x)\n",
    "    \n",
    "    slope = -1*(lmax - lmin)/(fmax - fmin)\n",
    "    \n",
    "    return ((x-lmin)/slope) + fmax\n",
    "\n",
    "def noCorrelation(lmin, lmax, fmin, fmax, x):\n",
    "    #doesn't actually need feature values or x\n",
    "    fmin = float(fmin)\n",
    "    fmax = float(fmax)\n",
    "    \n",
    "    return random.uniform(fmin, fmax)\n",
    "    \n",
    "\n",
    "    \n",
    "#print(linearNegative(0, 50, 60, 80, 25))\n",
    "#print(linearPositive(0, 50, 60, 80, 25))\n",
    "#print(gauss(12, 84, 47, 104, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRows = 1000\n",
    "outputFile = \"driving_cars.csv\"\n",
    "#percent of data for each feature that is just randomly generated rather than using model\n",
    "percentTotallyRandom = .01\n",
    "#amount that a particular point can deviate from its ideal position\n",
    "#written as a percent of the range of the feature\n",
    "#in other words: if a feature has a range of 10 and variance = 0.1, any point can be at most 1 unit away from ideal position\n",
    "variance = 0.01\n",
    "decimalPoints = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alert', 'Cars']\n",
      "{'id': 'Alert', 'type': 'continuous', 'values': {'min': 0, 'max': 100}}\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import csv\n",
    "import json\n",
    "\n",
    "headers = [field['id'] for field in data_descriptor_json['fields']]\n",
    "print(headers)\n",
    "\n",
    "print(fields[0])\n",
    "\n",
    "## Get metadata about label\n",
    "t = \"\"\n",
    "labelMin = 0\n",
    "labelMax = 0\n",
    "\n",
    "for f in fields:\n",
    "    if f['id'] == label:\n",
    "        t = type(f['values']['min'])\n",
    "        labelMin = f['values']['min']\n",
    "        labelMax = f['values']['max']\n",
    "        break\n",
    "        \n",
    "labelOut = []\n",
    "print(t)\n",
    "\n",
    "## Generate all the output values for my label\n",
    "for repeat in range(numRows):\n",
    "    if t is int:\n",
    "        labelOut.append(random.randint(labelMin, labelMax))\n",
    "    elif t is float:\n",
    "        labelOut.append(random.uniform(labelMin, labelMax))\n",
    "    else:\n",
    "        print(\"Error w/continuous types\")\n",
    "        \n",
    "rows = []\n",
    "## Repeat numRows times\n",
    "for i in range(numRows):\n",
    "    tempRow = []\n",
    "    curLabelVal = labelOut[i]\n",
    "    #curLabelVal = 12\n",
    "    ## For each field\n",
    "    for f in fields:\n",
    "        if f['id'] == label:\n",
    "            ## Found the label, so I can start adding the value from before\n",
    "            ## But first, need to add in the variance I got from before. \n",
    "            ## Need to add to the LABEL value since I want it to represent variance in the vertical / label output,\n",
    "            ## not variabce in the horizontal / feature output\n",
    "            ## (This comment is extra long because I had it backwards at one point)\n",
    "            varianceRange = (labelMax - labelMin) * variance\n",
    "            if t is int:\n",
    "                tempVal = random.randint(int(curLabelVal - varianceRange), int(curLabelVal + varianceRange))\n",
    "            elif t is float:\n",
    "                tempVal = random.uniform(curLabelVal - varianceRange, curLabelVal + varianceRange)\n",
    "            tempRow.append(tempVal)\n",
    "        else:\n",
    "            ## get feature metadata to generate\n",
    "            featureMin = f['values']['min']\n",
    "            featureMax = f['values']['max']\n",
    "            fType = type(featureMin)\n",
    "            corType = correlation_values[f['id']]\n",
    "            featureVal = 0\n",
    "            rand = random.random()\n",
    "            #if(rand < percentTotallyRandom):\n",
    "            #    featureVal = noCorrelation(labelMin, labelMax, featureMin, featureMax, curLabelVal)\n",
    "            #elif corType == \"gauss\":\n",
    "            if corType == \"gauss\":\n",
    "                featureVal = gauss(labelMin, labelMax, featureMin, featureMax, curLabelVal)\n",
    "            elif corType == \"linearPositive\":\n",
    "                featureVal = linearPositive(labelMin, labelMax, featureMin, featureMax, curLabelVal)\n",
    "            elif corType == \"linearNegative\":\n",
    "                featureVal = linearNegative(labelMin, labelMax, featureMin, featureMax, curLabelVal)\n",
    "            elif corType == \"noCorrelation\":\n",
    "                featureVal = noCorrelation(labelMin, labelMax, featureMin, featureMax, curLabelVal)\n",
    "            \n",
    "            #if random.randint(1, 2) == 1:\n",
    "            #    featureVal += featureVariance\n",
    "            #else:\n",
    "            #    featureVal -= featureVariance\n",
    "            \n",
    "            if fType is int:\n",
    "                featureVal = int(featureVal)\n",
    "            elif fType is float:\n",
    "                featureVal = round(featureVal, decimalPoints)\n",
    "            tempRow.append(featureVal)\n",
    "    rows.append(tempRow)\n",
    "\n",
    "#for row in rows:\n",
    "#    print(row)\n",
    "    \n",
    "with open(outputFile, 'w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=',')\n",
    "    writer.writerow(headers)\n",
    "    for row in rows:\n",
    "        writer.writerow(row)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outfile_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-845c4f127a0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#write the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_descriptor_json\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fields'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_descriptor_json\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fields'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'outfile_name' is not defined"
     ]
    }
   ],
   "source": [
    "# DON'T USE!!!!\n",
    "\n",
    "#write the file\n",
    "with open(outfile_name, 'w') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=',')\n",
    "    headers = [field['id'] for field in data_descriptor_json['fields']]\n",
    "    fields = data_descriptor_json['fields']\n",
    "    writer.writerow(headers)\n",
    "    result_index = headers.index(predict_label)\n",
    "    for i in range(num_rows):\n",
    "        output = {}\n",
    "        row = []\n",
    "        rand_num = random.random()\n",
    "        for i in fields:\n",
    "            if i['id'] != predict_label:\n",
    "                random_val = random.uniform(i['values']['min'], i['values']['max'])\n",
    "                output[i['id']] = round(random_val, decimal_points)\n",
    "        # quick pass at code for adding some degree of error to the \"correct\" predictions\n",
    "        # error_pos_neg = 1 if random.random() < 0.5 else -1\n",
    "        prediction = formula(output) \n",
    "        # predict_error = prediction * error_pos_neg * error\n",
    "        # output[predict_label] = round(prediction + predict_error, decimal_points)\n",
    "        if rand_num < error:\n",
    "            print(fields[result_index])\n",
    "            output[predict_label] = round(random.uniform(fields[result_index]['values']['min'], fields[result_index]['values']['min']), decimal_points)\n",
    "        else:\n",
    "            output[predict_label] = round(prediction, decimal_points)\n",
    "        for i in headers:\n",
    "            row.append(output[i])\n",
    "        writer.writerow(row)                                                     \n",
    "                    \n",
    "                                                \n",
    "                                                              \n",
    "                \n",
    "        \n",
    "                \n",
    "                \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
